DEFAULT_CONFIG = {
    "model": "llama2",  # Default model, can be changed based on what's available locally
    "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 40,
        "num_predict": 1000,
    }
}
